{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bayesian Logistic Regression with PyMC3\n\nIn this notebook we will be using pymc3 to examine posterior probability distributions for the parameters in logistic regression for classification.\n\nWe start by importing our required libraries.","metadata":{"editable":false}},{"cell_type":"code","source":"# This is a simple example of using pymc3 for Bayesian inference of the parameter distribution.\n# written by William F Basener\n# University of Virginia\n\nimport pymc3 as pm\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"execution":{"iopub.status.busy":"2022-04-07T04:43:38.138566Z","iopub.execute_input":"2022-04-07T04:43:38.138884Z","iopub.status.idle":"2022-04-07T04:43:45.769852Z","shell.execute_reply.started":"2022-04-07T04:43:38.138856Z","shell.execute_reply":"2022-04-07T04:43:45.768917Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"We define a function that will be helpful for plotting.  This function does little mathematically, but will give us very nice trace plots.","metadata":{"editable":false}},{"cell_type":"code","source":"def plot_traces(traces, retain=0):\n    '''\n    Convenience function:\n    Plot traces with overlaid means and values\n    '''\n\n    ax = pm.traceplot(traces[-retain:],\n                      lines=tuple([(k, {}, v['mean'])\n                                   for k, v in pm.summary(traces[-retain:]).iterrows()]))\n\n    for i, mn in enumerate(pm.summary(traces[-retain:])['mean']):\n        ax[i,0].annotate('{:.2f}'.format(mn), xy=(mn,0), xycoords='data'\n                    ,xytext=(5,10), textcoords='offset points', rotation=90\n                    ,va='bottom', fontsize='large', color='#AA0022')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:42:31.944121Z","iopub.execute_input":"2022-04-07T03:42:31.944419Z","iopub.status.idle":"2022-04-07T03:42:31.954699Z","shell.execute_reply.started":"2022-04-07T03:42:31.944384Z","shell.execute_reply":"2022-04-07T03:42:31.953653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the data and look a the data frame.","metadata":{"editable":false}},{"cell_type":"code","source":"data = pd.read_csv('../input/iris-flower-dataset/IRIS.csv')\ndata = data[['sepal_length','sepal_width','petal_length','petal_width','species']]\nprint(np.unique(data['species']))\ndata.describe()\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:42:31.955798Z","iopub.execute_input":"2022-04-07T03:42:31.956183Z","iopub.status.idle":"2022-04-07T03:42:32.042669Z","shell.execute_reply.started":"2022-04-07T03:42:31.956147Z","shell.execute_reply":"2022-04-07T03:42:32.041766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[data['species'] == 'Iris-setosa',:].mean()*10","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:42:32.044114Z","iopub.execute_input":"2022-04-07T03:42:32.044644Z","iopub.status.idle":"2022-04-07T03:42:32.084315Z","shell.execute_reply.started":"2022-04-07T03:42:32.044599Z","shell.execute_reply":"2022-04-07T03:42:32.083335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[data['species'] == 'Iris-setosa',:].cov()*10","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:42:32.085828Z","iopub.execute_input":"2022-04-07T03:42:32.086086Z","iopub.status.idle":"2022-04-07T03:42:32.108977Z","shell.execute_reply.started":"2022-04-07T03:42:32.086059Z","shell.execute_reply":"2022-04-07T03:42:32.108009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are using the seaborn plottng library.  This enables a very nice pairs plot for our classes.","metadata":{"editable":false}},{"cell_type":"code","source":"g = sns.pairplot(data, hue=\"species\", palette=\"husl\", markers=[\"o\", \"s\", \"D\"])","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:42:32.113099Z","iopub.execute_input":"2022-04-07T03:42:32.113363Z","iopub.status.idle":"2022-04-07T03:42:38.807667Z","shell.execute_reply.started":"2022-04-07T03:42:32.113335Z","shell.execute_reply":"2022-04-07T03:42:38.806572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we perform our MCMC computaiton.  With pymc3, this is very easy.  We use the usual \"with\" declaration for pymc3, then use glm for our logistic model and just have to specidfy the formula, the data, and the family.  The family is what tells pymc3 that this will be logistic regression.\n\nWe are going to use the default priors for GLM coefficients from PyMC3, which is $p(\\theta)=N(0,10^{12}I)$.  These are very weak priors.","metadata":{"editable":false}},{"cell_type":"code","source":"with pm.Model() as model:\n    pm.glm.GLM.from_formula(formula = 'species ~ sepal_length + sepal_width + petal_length + petal_width', \n                            data = data, \n                            family = pm.glm.families.Binomial())\n\n    trace = pm.sample(1000)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:42:38.811886Z","iopub.execute_input":"2022-04-07T03:42:38.812483Z","iopub.status.idle":"2022-04-07T03:44:51.34309Z","shell.execute_reply.started":"2022-04-07T03:42:38.812412Z","shell.execute_reply":"2022-04-07T03:44:51.341994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## I added this out of interest - I believe we discussed in class\n## Defines the same logistic regression as a member of the Generalized Linear Models (GLM) family \n\npm.model_to_graphviz(model)\n\n# See: https://goldinlocks.github.io/Bayesian-logistic-regression-with-pymc3/","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:51.344945Z","iopub.execute_input":"2022-04-07T03:44:51.345242Z","iopub.status.idle":"2022-04-07T03:44:51.621253Z","shell.execute_reply.started":"2022-04-07T03:44:51.345206Z","shell.execute_reply":"2022-04-07T03:44:51.619807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here are the variable names in the output.  ","metadata":{"editable":false}},{"cell_type":"code","source":"trace.varnames","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:51.623424Z","iopub.execute_input":"2022-04-07T03:44:51.62373Z","iopub.status.idle":"2022-04-07T03:44:51.630492Z","shell.execute_reply.started":"2022-04-07T03:44:51.623698Z","shell.execute_reply":"2022-04-07T03:44:51.629588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace_simple = trace","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:51.631985Z","iopub.execute_input":"2022-04-07T03:44:51.632519Z","iopub.status.idle":"2022-04-07T03:44:51.642917Z","shell.execute_reply.started":"2022-04-07T03:44:51.63247Z","shell.execute_reply":"2022-04-07T03:44:51.64213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.summary(trace)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:51.644299Z","iopub.execute_input":"2022-04-07T03:44:51.644751Z","iopub.status.idle":"2022-04-07T03:44:52.111272Z","shell.execute_reply.started":"2022-04-07T03:44:51.644714Z","shell.execute_reply":"2022-04-07T03:44:52.110066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here is our nice custom traceplot using the function plot_traces we defined previously.","metadata":{"editable":false}},{"cell_type":"code","source":"# PyMC3 trace is similar to an object that contains the output from MCMC sampling\nplot_traces(trace)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:52.112728Z","iopub.execute_input":"2022-04-07T03:44:52.113004Z","iopub.status.idle":"2022-04-07T03:44:56.133756Z","shell.execute_reply.started":"2022-04-07T03:44:52.112973Z","shell.execute_reply":"2022-04-07T03:44:56.132336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The creates a matplotlib plot, so we can modify with standard matplotlib commands\npm.plots.forestplot(trace, figsize=(12, 5))\nplt.grid()  # add a grid to the plot","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:56.135627Z","iopub.execute_input":"2022-04-07T03:44:56.135942Z","iopub.status.idle":"2022-04-07T03:44:57.281987Z","shell.execute_reply.started":"2022-04-07T03:44:56.135911Z","shell.execute_reply":"2022-04-07T03:44:57.281186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seaborn joint plot which plots datapairs for easy comparison\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['petal_length'], trace['petal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"petal_length\")\nplt.ylabel(\"petal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_length'], trace['sepal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"sepal_length\")\nplt.ylabel(\"sepal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_length'], trace['petal_width'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"petal_length\")\nplt.ylabel(\"sepal_width\");\nplt.show()\n\nplt.figure(figsize=(9,7))\nsns.jointplot(trace['sepal_length'], trace['petal_length'], kind=\"hex\", color=\"#4CB391\")\nplt.xlabel(\"sepal_length\")\nplt.ylabel(\"petal_width\");\nplt.show()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:44:57.283353Z","iopub.execute_input":"2022-04-07T03:44:57.283858Z","iopub.status.idle":"2022-04-07T03:45:00.973585Z","shell.execute_reply.started":"2022-04-07T03:44:57.283824Z","shell.execute_reply":"2022-04-07T03:45:00.972741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Q1\n## The results of our logistic regression model are expressed via three plots: a PyMC3 traceplot, a matplotlib forestplot, and a seaborn joint plot. In the trace plot, the predictor variables that are most likely to be zero are those with whose marginalized distribution plot (the plots on the left-hand side in the traceplot) includes zero. In this case, the sepal length and sepal width plots both include zero. Accordingly, they both have somelikelihood that coefficient could be zero. It's possible that sepal length could be slightly more likely to be zero because zero is slightly closer (visually) towards the center of the distribution that in the sepal width plot.\n\n## A similar conclusion can be drwn from examining the credible intervals in the forest plot. Both chains in the sepal length credible interval 'touch' the zero line. In the sepal width plot, one of the two chains touches the zero line, and the othert is very close to zero and much closer than any of the other variables' chains.\n\n## The jointplot plots two variables together. The darker hexagons in the plot indicate some relationship between the two dimensions. The darkest areas reflect the highest probabilities. Similar to the plots above, the plots that show darker hexes around or at zero have an increased probability of being zero. This can expressly be seen in the second plot (sepal length x sepal width) where colored/darker hexes are on around around zero on both axes.\n\n### See: https://docs.exoplanet.codes/en/latest/tutorials/intro-to-pymc3/","metadata":{"editable":false}},{"cell_type":"markdown","source":" ","metadata":{"editable":false}},{"cell_type":"markdown","source":"### Question 1 - Appendix -  I worked a little bit ahead with below.","metadata":{"editable":false}},{"cell_type":"code","source":"## Run Automatic Differentation Variational Inference (ADVI)\n## ADVI is an alternative method to CAVI to maximize the ELBO\n\nfrom pymc3.variational.callbacks import CheckParametersConvergence\nwith model:\n    callback = CheckParametersConvergence(diff='absolute')\n    approx = pm.fit(n=1000, callbacks=[callback])\n    \n# See: https://luiarthur.github.io/statorial/varinf/introvi/\n# See: https://goldinlocks.github.io/Bayesian-logistic-regression-with-pymc3/","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:00.974879Z","iopub.execute_input":"2022-04-07T03:45:00.975114Z","iopub.status.idle":"2022-04-07T03:45:40.599214Z","shell.execute_reply.started":"2022-04-07T03:45:00.975087Z","shell.execute_reply":"2022-04-07T03:45:40.598169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Persist result\nfrom pathlib import Path\nimport pickle\nfrom collections import OrderedDict\nwith open('model_advi.pkl', 'wb') as buff:\n    pickle.dump({'model': model,\n                 'approx': approx}, buff)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:40.602009Z","iopub.execute_input":"2022-04-07T03:45:40.602397Z","iopub.status.idle":"2022-04-07T03:45:40.64259Z","shell.execute_reply.started":"2022-04-07T03:45:40.602346Z","shell.execute_reply":"2022-04-07T03:45:40.641651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Draw samples from the approximated distribution to obtain a trace object as above for the MCMC sampler:\ntrace_advi = approx.sample(200)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:40.644855Z","iopub.execute_input":"2022-04-07T03:45:40.645316Z","iopub.status.idle":"2022-04-07T03:45:47.843133Z","shell.execute_reply.started":"2022-04-07T03:45:40.645272Z","shell.execute_reply":"2022-04-07T03:45:47.842056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.summary(trace_advi)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:47.844909Z","iopub.execute_input":"2022-04-07T03:45:47.845206Z","iopub.status.idle":"2022-04-07T03:45:48.085935Z","shell.execute_reply.started":"2022-04-07T03:45:47.845171Z","shell.execute_reply":"2022-04-07T03:45:48.085078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the covariance structure of the model\n# Professor Basener - I have some questions about this\n\nimport arviz as az\n\naz.plot_pair(trace_advi, figsize=(8, 8));","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:48.087401Z","iopub.execute_input":"2022-04-07T03:45:48.087693Z","iopub.status.idle":"2022-04-07T03:45:50.564146Z","shell.execute_reply.started":"2022-04-07T03:45:48.087664Z","shell.execute_reply":"2022-04-07T03:45:50.563314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 2. Logistic Regression for Predicting Coronary Heart Disease\n# Base Case - Logistic Regression\n\nNow lets apply some Bayesian Regression techniques to a healthcare problem of determining risk for Coronary Heart Disease.  Logistic Regression is a great method for this problem because it provides esitmates of probability of heart disease and the Bayesian analysis provides insight into uncertainty and importance of the different predicotr variables.","metadata":{"editable":false}},{"cell_type":"code","source":"chd_data = pd.read_csv(\"../input/coronary-heart-disease/CHDdata.csv\")\nchd_data.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:50.565768Z","iopub.execute_input":"2022-04-07T03:45:50.566078Z","iopub.status.idle":"2022-04-07T03:45:50.593116Z","shell.execute_reply.started":"2022-04-07T03:45:50.566045Z","shell.execute_reply":"2022-04-07T03:45:50.592416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chd_data.describe()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:50.594487Z","iopub.execute_input":"2022-04-07T03:45:50.594895Z","iopub.status.idle":"2022-04-07T03:45:50.639597Z","shell.execute_reply.started":"2022-04-07T03:45:50.594857Z","shell.execute_reply":"2022-04-07T03:45:50.638749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize the data (mean for each numerical variable of zero, standard deviation of one.)\nfor key in chd_data.keys()[0:9]:\n    try:\n        print(\"Standardizing \"+key+\".\")\n        chd_data[key] = chd_data[key] - np.mean(chd_data[key])\n        chd_data[key] = chd_data[key] / np.std(chd_data[key])\n    except:\n        print(\"Predictor \"+key+\" cannot be standardized (probably a categorical variable).\")\nchd_data.describe()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:50.640867Z","iopub.execute_input":"2022-04-07T03:45:50.641122Z","iopub.status.idle":"2022-04-07T03:45:50.71481Z","shell.execute_reply.started":"2022-04-07T03:45:50.641093Z","shell.execute_reply":"2022-04-07T03:45:50.713931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets check the mean of each class to get a first look at the separation\nprint(\"Mean for CHD Positive:\")\nprint(np.array([chd_data[chd_data.chd == 1].mean()[0:8]]))\nprint(\"Mean for CHD Negative:\")\nprint(np.array([chd_data[chd_data.chd == 0].mean()[0:8]]))","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:50.716259Z","iopub.execute_input":"2022-04-07T03:45:50.716541Z","iopub.status.idle":"2022-04-07T03:45:50.739151Z","shell.execute_reply.started":"2022-04-07T03:45:50.716509Z","shell.execute_reply":"2022-04-07T03:45:50.738396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chd_data.head()","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:45:50.740275Z","iopub.execute_input":"2022-04-07T03:45:50.740678Z","iopub.status.idle":"2022-04-07T03:45:50.75827Z","shell.execute_reply.started":"2022-04-07T03:45:50.740648Z","shell.execute_reply":"2022-04-07T03:45:50.757582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Create Logistic Regression model with CHD dataset - with priors","metadata":{"editable":false}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"with pm.Model() as model:\n    # Define priors for intercept & regression coefficients\n    # x5 is categorical predictor 'famhist' - using uninformative prior\n    # Note however the source footnoted below - \"there is no such thing as\n    # an uninformative (beta (prior)\"\n    \n    priors = {\n        \"Intercept\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"sbp\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"tobacco\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"ldl\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"adiposity\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"famhist\": pm.Beta.dist(alpha=1.0, beta=1.0),\n        \"typea\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"obesity\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"alcohol\": pm.Normal.dist(mu=0.0, sigma=1.0),\n        \"age\": pm.Normal.dist(mu=0.0, sigma=1.0),\n    }\n    pm.glm.GLM.from_formula(formula = 'chd ~ sbp + tobacco + ldl + adiposity + famhist + typea + obesity + alcohol + age', \n                            data = chd_data, \n                            family = pm.glm.families.Normal())\n\n    #trace = pm.sample(5000) \n    approx = pm.fit(50000, method = 'advi')\n    \n# See: https://stats.stackexchange.com/questions/297901/choosing-between-uninformative-beta-priors\n# See: https://docs.pymc.io/projects/examples/en/latest/generalized_linear_models/GLM-out-of-sample-predictions.html?highlight=family\n# See: https://docs.pymc.io/en/v3/pymc-examples/examples/generalized_linear_models/GLM-model-selection.html?highlight=family\n\nadvi_elbo = pd.DataFrame(\n    {'ELBO': -approx.hist,\n     'n': np.arange(approx.hist.shape[0])})\n\n_ = sns.lineplot(y='ELBO', x='n', data=advi_elbo)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace_VI = approx.sample(draws=5000)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:00.164402Z","iopub.execute_input":"2022-04-07T03:47:00.164712Z","iopub.status.idle":"2022-04-07T03:47:01.425906Z","shell.execute_reply.started":"2022-04-07T03:47:00.164677Z","shell.execute_reply":"2022-04-07T03:47:01.424554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_traces(trace_VI)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:01.429689Z","iopub.execute_input":"2022-04-07T03:47:01.429993Z","iopub.status.idle":"2022-04-07T03:47:14.757626Z","shell.execute_reply.started":"2022-04-07T03:47:01.429963Z","shell.execute_reply":"2022-04-07T03:47:14.756707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The creates a matplotlib plot, so we can modify with standard matplotlib commands\npm.plots.forestplot(trace_VI, figsize=(12, 5))\nplt.grid()  # add a grid to the plot","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:14.759067Z","iopub.execute_input":"2022-04-07T03:47:14.75931Z","iopub.status.idle":"2022-04-07T03:47:17.138011Z","shell.execute_reply.started":"2022-04-07T03:47:14.759281Z","shell.execute_reply":"2022-04-07T03:47:17.137237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.summary(trace_VI).round(2)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:17.139423Z","iopub.execute_input":"2022-04-07T03:47:17.139958Z","iopub.status.idle":"2022-04-07T03:47:18.504944Z","shell.execute_reply.started":"2022-04-07T03:47:17.139914Z","shell.execute_reply":"2022-04-07T03:47:18.504016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nax = sns.kdeplot(trace[\"x\"], label=\"NUTS\")\nsns.kdeplot(approx.sample(10000)[\"x\"], label=\"ADVI\");","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import arviz as az\n\n#az.plot_posterior(trace_approx.sample(10000));\naz.plot_posterior(trace_VI);\n\n# See: https://docs.pymc.io/en/v3/pymc-examples/examples/variational_inference/variational_api_quickstart.html","metadata":{"execution":{"iopub.status.busy":"2022-04-07T03:47:18.567671Z","iopub.status.idle":"2022-04-07T03:47:18.568491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ","metadata":{"execution":{"iopub.status.busy":"2022-04-06T05:00:53.161339Z","iopub.execute_input":"2022-04-06T05:00:53.161686Z","iopub.status.idle":"2022-04-06T05:00:53.517009Z","shell.execute_reply.started":"2022-04-06T05:00:53.161653Z","shell.execute_reply":"2022-04-06T05:00:53.516115Z"},"editable":false}},{"cell_type":"markdown","source":"# Original Logistic Regression Model - no priors","metadata":{"editable":false}},{"cell_type":"code","source":"with pm.Model() as model:\n    pm.glm.GLM.from_formula(formula = 'chd ~ sbp + tobacco + ldl + adiposity + typea + obesity + alcohol + age + famhist', \n                            data = chd_data, \n                            family = pm.glm.families.Binomial())\n\n    #trace = pm.sample(5000) \n    approx = pm.fit(50000, method = 'advi')","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:18.570056Z","iopub.status.idle":"2022-04-07T03:47:18.570848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"advi_elbo = pd.DataFrame(\n    {'ELBO': -approx.hist,\n     'n': np.arange(approx.hist.shape[0])})\n\n_ = sns.lineplot(y='ELBO', x='n', data=advi_elbo)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:18.572299Z","iopub.status.idle":"2022-04-07T03:47:18.572698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trace_VII = approx.sample(draws=5000)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:18.573891Z","iopub.status.idle":"2022-04-07T03:47:18.574226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_traces(trace_VII)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:18.575325Z","iopub.status.idle":"2022-04-07T03:47:18.575739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The creates a matplotlib plot, so we can modify with standard matplotlib commands\npm.plots.forestplot(trace_VII, figsize=(12, 5))\nplt.grid()  # add a grid to the plot","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:18.576852Z","iopub.status.idle":"2022-04-07T03:47:18.577193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pm.summary(trace_VII).round(2)","metadata":{"editable":false,"execution":{"iopub.status.busy":"2022-04-07T03:47:18.578187Z","iopub.status.idle":"2022-04-07T03:47:18.578566Z"},"trusted":true},"execution_count":null,"outputs":[]}]}